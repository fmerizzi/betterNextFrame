{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9fa20a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 09:18:53.511238: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-15 09:18:53.544463: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from transformer_video import VideoPrediction\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_movies(n_samples=1200, n_frames=20):\n",
    "    row = 80\n",
    "    col = 80\n",
    "    noisy_movies = np.zeros((n_samples, n_frames, row, col, 1), dtype=float)\n",
    "    shifted_movies = np.zeros((n_samples, n_frames, row, col, 1),\n",
    "                              dtype=float)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # Add 3 to 7 moving squares\n",
    "        n = np.random.randint(3, 8)\n",
    "\n",
    "        for j in range(n):\n",
    "            # Initial position\n",
    "            xstart = np.random.randint(20, 60)\n",
    "            ystart = np.random.randint(20, 60)\n",
    "            # Direction of motion\n",
    "            directionx = np.random.randint(0, 3) - 1\n",
    "            directiony = np.random.randint(0, 3) - 1\n",
    "\n",
    "            # Size of the square\n",
    "            w = np.random.randint(2, 4)\n",
    "\n",
    "            for t in range(n_frames):\n",
    "                x_shift = xstart + directionx * t\n",
    "                y_shift = ystart + directiony * t\n",
    "\n",
    "                # Shift the ground truth by 1\n",
    "                x_shift = xstart + directionx * (t + 1)\n",
    "                y_shift = ystart + directiony * (t + 1)\n",
    "                shifted_movies[i, t, x_shift - w: x_shift + w,\n",
    "                               y_shift - w: y_shift + w, 0] += 1\n",
    "\n",
    "    # Cut to a 40x40 window\n",
    "    shifted_movies = shifted_movies[::, ::, 20:60, 20:60, ::]\n",
    "    shifted_movies[shifted_movies >= 1] = 1\n",
    "    return shifted_movies\n",
    "    \n",
    "    \n",
    "def load_dataset(path, filename):\n",
    "    train_data = np.load(path + filename)\n",
    "    train_data = train_data.swapaxes(0, 1)[:100]\n",
    "    # train_data[[1005, 9000]] = train_data[[9000, 1005]]\n",
    "\n",
    "    # patch size 2 x 2\n",
    "    # train_data = train_data.reshape(train_data.shape[0], train_data.shape[1], 16, 16, 16)\n",
    "    #train_data = reshape_patch(train_data, (2, 2))\n",
    "    #plt.imshow(restore_patch(train_data[0], (2, 2))[0])\n",
    "    #plt.show()\n",
    "    \n",
    "    train_data[train_data < 128] = 0\n",
    "    train_data[train_data >= 128] = 1\n",
    "    #train_data = train_data / 255.0\n",
    "    print(train_data.shape)\n",
    "    \n",
    "    train_data = np.expand_dims(train_data, axis=4)\n",
    "    X = train_data[:, :10, :, :, :]\n",
    "    Y = train_data[:, 10:21, :, :, :]\n",
    "    \n",
    "\n",
    "    X = tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "    Y = tf.convert_to_tensor(Y, dtype=tf.float32)\n",
    "    \n",
    "    return (X, Y)\n",
    "    \n",
    "def plot_result(input_, actual, predict):\n",
    "    \n",
    "        \n",
    "    for i in range(actual.shape[0]):\n",
    "        plt.subplot(121), plt.imshow(actual[i]),\n",
    "        plt.title(\"Actual_\" + str(i + 1 + input_.shape[0]))\n",
    "        plt.subplot(122), plt.imshow(predict[i]),\n",
    "        plt.title(\"Predicted_\" + str(i + 1 + input_.shape[0]))\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "455a3d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load('/home/faster/Documents/wind_prediction/10m_u-component_of_wind_2022_hourly.npz')['arr_0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2daa773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.expand_dims(dataset, axis=-1)\n",
    "dataset = (dataset - dataset.min(axis=0)) / (dataset.max(axis=0) - dataset.min(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec157242",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[:,:,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83c51964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(730, 12, 201, 201, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb4f6140",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#shifted_movies = tf.convert_to_tensor(generate_movies(n_samples=1200), dtype=tf.float32)\n",
    "#print(shifted_movies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8eb5c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 09:19:00.975195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-15 09:19:00.987687: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-15 09:19:00.988209: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-15 09:19:00.988964: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-15 09:19:00.990978: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-15 09:19:00.991474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-15 09:19:00.991926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-15 09:19:01.253915: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-15 09:19:01.254413: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-15 09:19:01.254869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-15 09:19:01.255304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13763 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#X = shifted_movies[:, :10, :, :, :]\n",
    "#Y = shifted_movies[:, 10:, :, :, :]\n",
    "X = dataset[:, :6, :, :, :]\n",
    "Y = dataset[:, 6:, :, :, :]\n",
    "\n",
    "# defines the model\n",
    "model = VideoPrediction(\n",
    "    num_layers=2, d_model=64, num_heads=16, dff=128,\n",
    "    filter_size=(5, 5), image_shape=(201, 201), pe_input=10,\n",
    "    pe_target=20, out_channel=1, loss_function='bin_cross'\n",
    ")\n",
    "\n",
    "# training on first 1000 samples\n",
    "# samples from 1000 - 1199 are used as test set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efdbcb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 09:19:02.456558: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n",
      "2023-03-15 09:19:03.053606: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-15 09:19:03.053893: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-15 09:19:03.053905: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-03-15 09:19:03.054210: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-15 09:19:03.054231: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 0.6638\n",
      "Time taken for 1 epoch 167.30358695983887 sec\n",
      "\n",
      "Epoch 2 Loss 0.6388\n",
      "Time taken for 1 epoch 162.16580319404602 sec\n",
      "\n",
      "Epoch 3 Loss 0.6299\n",
      "Time taken for 1 epoch 162.24408316612244 sec\n",
      "\n",
      "Epoch 4 Loss 0.6301\n",
      "Time taken for 1 epoch 162.37160325050354 sec\n",
      "\n",
      "Epoch 5 Loss 0.6258\n",
      "Time taken for 1 epoch 161.6639211177826 sec\n",
      "\n",
      "Epoch 6 Loss 0.6247\n",
      "Time taken for 1 epoch 160.56168723106384 sec\n",
      "\n",
      "Epoch 7 Loss 0.6244\n",
      "Time taken for 1 epoch 160.68697571754456 sec\n",
      "\n",
      "Epoch 8 Loss 0.6243\n",
      "Time taken for 1 epoch 160.8771150112152 sec\n",
      "\n",
      "Epoch 9 Loss 0.6241\n",
      "Time taken for 1 epoch 160.06910395622253 sec\n",
      "\n",
      "Epoch 10 Loss 0.6240\n",
      "Time taken for 1 epoch 160.93549942970276 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.train(X[:700, :3], X[:700, 3:], None, None, 10, 1,epoch_print=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "288fa9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.transformer.save_weights('./2lfil5-5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f99f7e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 18:38:42.507909: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.25GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 0.7631\n"
     ]
    }
   ],
   "source": [
    "test_loss = model.evaluate(X[100:300], Y[100:300], 8)\n",
    "print('Test Loss {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99731c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 1.7469\n"
     ]
    }
   ],
   "source": [
    "test_loss = model.evaluate(X[100:300], Y[100:300], 8)\n",
    "print('Test Loss {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b61e4694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 0.8666\n"
     ]
    }
   ],
   "source": [
    "test_loss = model.evaluate(X[100:300], Y[100:300], 8)\n",
    "print('Test Loss {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "043af117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import imageio\n",
    "from IPython.display import Image, display\n",
    "from ipywidgets import widgets, Layout, HBox\n",
    "\n",
    "\n",
    "x1 = tf.concat((X[242], Y[242]), axis=0)\n",
    "x2 = tf.concat((X[414], Y[414]), axis=0)\n",
    "y1 = model.predict(x1[:6], 6)\n",
    "y2 = model.predict(x2[:6], 6)\n",
    "x1 = x1.numpy().reshape(12, 201, 201)\n",
    "x2 = x2.numpy().reshape(12, 201, 201)\n",
    "\n",
    "from datetime import datetime\n",
    "images = []\n",
    "for i in range(y1.shape[0]):\n",
    "    images.append((np.squeeze(x1[i]) * 255).astype('uint8'))\n",
    "imageio.mimsave(str(datetime.now())+'x.gif', images,fps=2)\n",
    "\n",
    "images = []\n",
    "for i in range(y1.shape[0]):\n",
    "    images.append((np.squeeze(y1[i]) * 255).astype('uint8'))\n",
    "imageio.mimsave(str(datetime.now())+'y.gif', images,fps=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27cdf2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import imageio\n",
    "from IPython.display import Image, display\n",
    "from ipywidgets import widgets, Layout, HBox\n",
    "\n",
    "\n",
    "x1 = tf.concat((X[111], Y[111]), axis=0)\n",
    "y1 = model.predict(x1[:6], 20)\n",
    "x1 = x1.numpy().reshape(12, 201, 201)\n",
    "\n",
    "from datetime import datetime\n",
    "images = []\n",
    "for i in range(x1.shape[0]):\n",
    "    images.append((np.squeeze(x1[i]) * 255).astype('uint8'))\n",
    "imageio.mimsave(str(datetime.now())+'x.gif', images,fps=2)\n",
    "\n",
    "images = []\n",
    "for i in range(y1.shape[0]):\n",
    "    images.append((np.squeeze(y1[i]) * 255).astype('uint8'))\n",
    "imageio.mimsave(str(datetime.now())+'y.gif', images,fps=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c64dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
